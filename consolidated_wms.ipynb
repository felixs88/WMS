{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy import Selector\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "from weather import Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "search_text = \"Coimbatore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Yahoo Weather Information</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yahoo', 27, 29, 28, 28, 28, 27)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    weather = Weather()\n",
    "    location = weather.lookup_by_location(search_text)\n",
    "    condition = location.condition()\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), \"\", \"\", \"\")\n",
    "\n",
    "    yahoo_url = \"https://query.yahooapis.com/v1/public/yql?\"\n",
    "    yql_query = \"select * from weather.forecast where woeid in (select woeid from geo.places(1) where text='{}')\".format(search_text)\n",
    "    yql_url = yahoo_url + urllib.urlencode({'q':yql_query}) + \"&format=json\"\n",
    "    result = urllib2.urlopen(yql_url).read()\n",
    "    data = json.loads(result)\n",
    "\n",
    "    week_data = data['query']['results'][\"channel\"][\"item\"][\"forecast\"]\n",
    "    day_1 = int((int(week_data[1]['high']) - 32) * 0.5556)\n",
    "    day_2 = int((int(week_data[2]['high']) - 32) * 0.5556)\n",
    "    day_3 = int((int(week_data[3]['high']) - 32) * 0.5556)\n",
    "    day_4 = int((int(week_data[4]['high']) - 32) * 0.5556)\n",
    "    day_5 = int((int(week_data[5]['high']) - 32) * 0.5556)\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), day_1, day_2, day_3, day_4, day_5)\n",
    "except:\n",
    "    yahoo_data_now = (\n",
    "        \"Yahoo\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print yahoo_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>The Weather Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.theweathernetwork.com/in/api/location/search?searchText={}\".format(search_text)\n",
    "req = requests.get(base_url)\n",
    "\n",
    "data = req.json()\n",
    "data_url = []\n",
    "if data:\n",
    "    for i in data:\n",
    "        if i[\"name\"] == search_text.title() and i[\"country\"] == \"India\":\n",
    "            each_url = \"https://www.theweathernetwork.com{}\".format(i[\"url\"])            \n",
    "            data_url.append({\"each_url\": each_url, \"code\": i[\"code\"]})\n",
    "\n",
    "try:            \n",
    "    if data_url:\n",
    "    \n",
    "        req_url = data_url[0]\n",
    "        current_weather_url = \"https://www.theweathernetwork.com/in/api/savedlocation/index/?placecodes={}\".format(req_url[\"code\"])\n",
    "        current_weather_req = requests.get(current_weather_url).json()\n",
    "        current_day_temp = current_weather_req[0][\"temperature\"]\n",
    "    \n",
    "        resp = urllib2.urlopen(req_url[\"each_url\"]).read()\n",
    "        soup = BeautifulSoup(resp, \"lxml\")\n",
    "    \n",
    "        current_data_day_1 = soup.find_all(\"div\", attrs={\"class\": \"day_1\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_1[0])\n",
    "        selection_day_1 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_1 = re.findall(\"\\d+\", selection_day_1[5])[0]\n",
    "\n",
    "        current_data_day_2 = soup.find_all(\"div\", attrs={\"class\": \"day_2\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_2[0])\n",
    "        selection_day_2 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_2 = re.findall(\"\\d+\", selection_day_2[5])[0]\n",
    "\n",
    "        current_data_day_3 = soup.find_all(\"div\", attrs={\"class\": \"day_3\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_3[0])\n",
    "        selection_day_3 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_3 = re.findall(\"\\d+\", selection_day_3[5])[0]\n",
    "\n",
    "        current_data_day_4 = soup.find_all(\"div\", attrs={\"class\": \"day_4\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_4[0])\n",
    "        selection_day_4 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_4 = re.findall(\"\\d+\", selection_day_4[5])[0]\n",
    "\n",
    "        current_data_day_5 = soup.find_all(\"div\", attrs={\"class\": \"day_5\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_5[0])\n",
    "        selection_day_5 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_5 = re.findall(\"\\d+\", selection_day_5[5])[0]\n",
    "\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            current_day_temp,\n",
    "            temp_day_1,\n",
    "            temp_day_2,\n",
    "            temp_day_3,\n",
    "            temp_day_4,\n",
    "            temp_day_5,\n",
    "        )\n",
    "    else:\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "        )\n",
    "except:\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "        )\n",
    "    \n",
    "#url = req.json()[0]['url']\n",
    "#code = req.json()[0]['code']\n",
    "\n",
    "#ddict = defaultdict(list)\n",
    "\n",
    "#for i in data:\n",
    "#    if ddict[i[\"countrycode\"]]:\n",
    "#        ddict[i[\"countrycode\"]].append(i)\n",
    "#    else:\n",
    "#        ddict[i[\"countrycode\"]] = []\n",
    "#        ddict[i[\"countrycode\"]].append(i)\n",
    "\n",
    "#info_urls = []        \n",
    "#for k in ddict[\"IN\"]:\n",
    "#    if k[\"name\"] == search_text.title():\n",
    "#        info_urls.append(k['code'])\n",
    "        \n",
    "#print info_urls        \n",
    "#try:\n",
    "#    if info_urls:\n",
    "#        data = \"https://www.theweathernetwork.com/in/api/savedlocation/index/?placecodes={}\".format(info_urls[0])\n",
    "#        print data\n",
    "#        url_req = requests.get(data)\n",
    "#        print url_req.json()\n",
    "#        temperature = url_req.json()[0]['temperature']\n",
    "#        feels_like = url_req.json()[0]['feels_like']\n",
    "#        updated = url_req.json()[0]['updatetime']\n",
    "#        weather_network_data_now = (\"Weather Network\", str(temperature), \"\", \"\", \"\", \"\", \"\")\n",
    "#    else:\n",
    "#        weather_network_data_now = (\n",
    "#            \"Weather Network\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#        )\n",
    "#except:\n",
    "#    weather_network_data_now = (\n",
    "#        \"Weather Network\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Foundr\",\n",
    "#        \"Not Found\",\n",
    "#    )\n",
    "#print weather_network_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> MSN Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MSN Weather', 30, 31, 31, 30, '', '')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    base_url = \"http://weather.service.msn.com/data.aspx?weasearchstr={}&culture=en-US&weadegreetype=F&src=outlook\".format(search_text)\n",
    "    req = requests.get(base_url)\n",
    "    root = ET.fromstring(req.content)\n",
    "    data = root.__dict__['_children'][0].__dict__['_children'][0].__dict__['attrib']\n",
    "    data_1 = root.__dict__['_children'][0].__dict__[\"_children\"][3].__dict__['attrib']['high']\n",
    "    data_2 = root.__dict__['_children'][0].__dict__[\"_children\"][4].__dict__['attrib']['high']\n",
    "    data_3 = root.__dict__['_children'][0].__dict__[\"_children\"][5].__dict__['attrib']['high']\n",
    "    msn_weather_now = (\n",
    "        \"MSN Weather\",\n",
    "        int((int(data['temperature'])-32)*float(0.5556)),\n",
    "        int((int(data_1)-32)*float(0.5556)),\n",
    "        int((int(data_2)-32)*float(0.5556)),\n",
    "        int((int(data_3)-32)*float(0.5556)),\n",
    "        \"\",\n",
    "        \"\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    msn_weather_now = (\n",
    "        \"MSN Weather\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print msn_weather_now    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Accurate Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accurate Weather', '32', '31', '30', '30', '', '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:26: ScrapyDeprecationWarning: scrapy.selector.HtmlXPathSelector is deprecated, instantiate scrapy.Selector instead.\n"
     ]
    }
   ],
   "source": [
    "search_url = \"https://www.accuweather.com/en/search-locations\"\n",
    "search_data = {\"s\": search_text.title()}\n",
    "try:\n",
    "    req = requests.post(search_url, search_data)\n",
    "    resp = req.__dict__['_content']\n",
    "\n",
    "    soup = BeautifulSoup(resp, \"lxml\")\n",
    "    data_input_box = soup.find_all(\"input\", attrs={'id': 's'})\n",
    "\n",
    "    data_str = str(data_input_box[0])\n",
    "    data_url = re.findall(\"(https://www.accuweather.com/\\w+/\\w+/\\w+/[0-9]+/[\\w-]+/[0-9]+)\\\"\", data_str)[0]\n",
    "\n",
    "    base_url = data_url.replace(\"weather-forecast\", \"current-weather\")\n",
    "    base_link_url = base_url.replace(\"current-weather\", \"daily-weather-forecast\")\n",
    "    base_links = [\"{}?day={}\".format(base_link_url, i) for i in range(1, 6)]\n",
    "\n",
    "    req = urllib2.Request(base_url)\n",
    "    read_url = urllib2.urlopen(req)\n",
    "    response = read_url.read()\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    five_day_data = soup.find_all(\"li\", attrs={'data-href': base_links})\n",
    "\n",
    "    column_header = ('Day', 'Date', 'real_feel', 'precipitation', 'description')\n",
    "    data = []\n",
    "    for day in five_day_data:\n",
    "        hxs = HtmlXPathSelector(day).xpath(\"/html/body/p/text()\").extract()\n",
    "        doc = \"\"\"{}\"\"\".format(hxs[0].encode(\"utf-8\"))\n",
    "        each_day = re.sub(\"\\n+\",\n",
    "                          \",\",\n",
    "                          doc.decode(\"unicode_escape\").encode(\"ascii\", \"ignore\").replace(\"/\", \"\").replace(\"More\", \"\")\n",
    "                         )\n",
    "        data.append(filter(None, tuple(each_day.split(\",\")))) \n",
    "    accurate_weather_now = (\"Accurate Weather\", data[0][2], data[1][2], data[3][2], data[4][2], \"\", \"\")\n",
    "except:\n",
    "    accurate_weather_now = (\n",
    "        \"Accurate Weather\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print accurate_weather_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Consolidated Weather Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coimbatore\n",
      "\n",
      "                 Current Weather Day_1 Day_2 Day_3 Day_4 Day_5\n",
      "Sites                                                         \n",
      "Yahoo                         27    29    28    28    28    27\n",
      "MSN Weather                   30    31    31    30            \n",
      "Weather Network               30    33    32    32    30    30\n",
      "Accurate Weather              32    31    30    30            \n"
     ]
    }
   ],
   "source": [
    "header = (\"Sites\", \"Current Weather\", \"Day_1\", \"Day_2\", \"Day_3\", \"Day_4\", \"Day_5\")\n",
    "dataset = [yahoo_data_now, msn_weather_now, weather_network_data_now, accurate_weather_now]\n",
    "df = pd.DataFrame(data=dataset, columns=header,)\n",
    "print search_text.title()+\"\\n\"\n",
    "print df.set_index(\"Sites\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
