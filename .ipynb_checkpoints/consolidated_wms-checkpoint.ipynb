{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy import Selector\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "from weather import Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_text = \"Bangalore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Yahoo Weather Information</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yahoo', 24, 26, 27, 28, 26, 27)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    weather = Weather()\n",
    "    location = weather.lookup_by_location(search_text)\n",
    "    condition = location.condition()\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), \"\", \"\", \"\")\n",
    "\n",
    "    yahoo_url = \"https://query.yahooapis.com/v1/public/yql?\"\n",
    "    yql_query = \"select * from weather.forecast where woeid in (select woeid from geo.places(1) where text='{}')\".format(search_text)\n",
    "    yql_url = yahoo_url + urllib.urlencode({'q':yql_query}) + \"&format=json\"\n",
    "    result = urllib2.urlopen(yql_url).read()\n",
    "    data = json.loads(result)\n",
    "\n",
    "    week_data = data['query']['results'][\"channel\"][\"item\"][\"forecast\"]\n",
    "    day_1 = int((int(week_data[1]['high']) - 32) * 0.5556)\n",
    "    day_2 = int((int(week_data[2]['high']) - 32) * 0.5556)\n",
    "    day_3 = int((int(week_data[3]['high']) - 32) * 0.5556)\n",
    "    day_4 = int((int(week_data[4]['high']) - 32) * 0.5556)\n",
    "    day_5 = int((int(week_data[5]['high']) - 32) * 0.5556)\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), day_1, day_2, day_3, day_4, day_5)\n",
    "except:\n",
    "    yahoo_data_now = (\n",
    "        \"Yahoo\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print yahoo_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The Weather Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weather Network', 'Not Found', 'Not Found', 'Not Found', 'Not Found', 'Not Found', 'Not Found')\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.theweathernetwork.com/in/api/location/search?searchText={}\".format(search_text)\n",
    "req = requests.get(base_url)\n",
    "url = req.json()[0]['url']\n",
    "code = req.json()[0]['code']\n",
    "\n",
    "data = req.json()\n",
    "ddict = defaultdict(list)\n",
    "\n",
    "for i in data:\n",
    "    if ddict[i[\"countrycode\"]]:\n",
    "        ddict[i[\"countrycode\"]].append(i)\n",
    "    else:\n",
    "        ddict[i[\"countrycode\"]] = []\n",
    "        ddict[i[\"countrycode\"]].append(i)\n",
    "\n",
    "info_urls = []        \n",
    "for k in ddict[\"IN\"]:\n",
    "    if k[\"name\"] == search_text.title():\n",
    "        info_urls.append(k['code'])\n",
    "try:\n",
    "    if info_urls:\n",
    "        data = \"https://www.theweathernetwork.com/in/api/savedlocation/index/?placecodes={}\".format(info_urls[0])\n",
    "        url_req = requests.get(data)\n",
    "        temperature = url_req.json()[0]['temperature']\n",
    "        feels_like = url_req.json()[0]['feels_like']\n",
    "        updated = url_req.json()[0]['updatetime']\n",
    "        weather_network_data_now = (\"Weather Network\", str(temperature), \"\", \"\", \"\", \"\", \"\")\n",
    "    else:\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "        )\n",
    "except:\n",
    "    weather_network_data_now = (\n",
    "        \"Weather Network\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Foundr\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print weather_network_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> MSN Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MSN Weather', 22, 27, 27, 28, '', '')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    base_url = \"http://weather.service.msn.com/data.aspx?weasearchstr={}&culture=en-US&weadegreetype=F&src=outlook\".format(search_text)\n",
    "    req = requests.get(base_url)\n",
    "    root = ET.fromstring(req.content)\n",
    "    data = root.__dict__['_children'][0].__dict__['_children'][0].__dict__['attrib']\n",
    "    data_1 = root.__dict__['_children'][0].__dict__[\"_children\"][3].__dict__['attrib']['high']\n",
    "    data_2 = root.__dict__['_children'][0].__dict__[\"_children\"][4].__dict__['attrib']['high']\n",
    "    data_3 = root.__dict__['_children'][0].__dict__[\"_children\"][5].__dict__['attrib']['high']\n",
    "    msn_weather_now = (\n",
    "        \"MSN Weather\",\n",
    "        int((int(data['temperature'])-32)*float(0.5556)),\n",
    "        int((int(data_1)-32)*float(0.5556)),\n",
    "        int((int(data_2)-32)*float(0.5556)),\n",
    "        int((int(data_3)-32)*float(0.5556)),\n",
    "        \"\",\n",
    "        \"\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    msn_weather_now = (\n",
    "        \"MSN Weather\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print msn_weather_now    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Accurate Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accurate Weather', '28', '28', '28', '27', '', '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:26: ScrapyDeprecationWarning: scrapy.selector.HtmlXPathSelector is deprecated, instantiate scrapy.Selector instead.\n",
      "/usr/local/lib/python2.7/dist-packages/parsel/selector.py:234: ScrapyDeprecationWarning: scrapy.selector.HtmlXPathSelector is deprecated, instantiate scrapy.Selector instead.\n",
      "  for x in result]\n"
     ]
    }
   ],
   "source": [
    "search_url = \"https://www.accuweather.com/en/search-locations\"\n",
    "search_data = {\"s\": search_text.title()}\n",
    "try:\n",
    "    req = requests.post(search_url, search_data)\n",
    "    resp = req.__dict__['_content']\n",
    "\n",
    "    soup = BeautifulSoup(resp, \"lxml\")\n",
    "    data_input_box = soup.find_all(\"input\", attrs={'id': 's'})\n",
    "\n",
    "    data_str = str(data_input_box[0])\n",
    "    data_url = re.findall(\"(https://www.accuweather.com/\\w+/\\w+/\\w+/[0-9]+/[\\w-]+/[0-9]+)\\\"\", data_str)[0]\n",
    "\n",
    "    base_url = data_url.replace(\"weather-forecast\", \"current-weather\")\n",
    "    base_link_url = base_url.replace(\"current-weather\", \"daily-weather-forecast\")\n",
    "    base_links = [\"{}?day={}\".format(base_link_url, i) for i in range(1, 6)]\n",
    "\n",
    "    req = urllib2.Request(base_url)\n",
    "    read_url = urllib2.urlopen(req)\n",
    "    response = read_url.read()\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    five_day_data = soup.find_all(\"li\", attrs={'data-href': base_links})\n",
    "\n",
    "    column_header = ('Day', 'Date', 'real_feel', 'precipitation', 'description')\n",
    "    data = []\n",
    "    for day in five_day_data:\n",
    "        hxs = HtmlXPathSelector(day).xpath(\"/html/body/p/text()\").extract()\n",
    "        doc = \"\"\"{}\"\"\".format(hxs[0].encode(\"utf-8\"))\n",
    "        each_day = re.sub(\"\\n+\",\n",
    "                          \",\",\n",
    "                          doc.decode(\"unicode_escape\").encode(\"ascii\", \"ignore\").replace(\"/\", \"\").replace(\"More\", \"\")\n",
    "                         )\n",
    "        data.append(filter(None, tuple(each_day.split(\",\")))) \n",
    "    accurate_weather_now = (\"Accurate Weather\", data[0][2], data[1][2], data[3][2], data[4][2], \"\", \"\")\n",
    "except:\n",
    "    accurate_weather_now = (\n",
    "        \"Accurate Weather\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print accurate_weather_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Consolidated Weather Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore\n",
      "\n",
      "                 Current Weather      Day_1      Day_2      Day_3      Day_4  \\\n",
      "Sites                                                                          \n",
      "Yahoo                         24         26         27         28         26   \n",
      "MSN Weather                   22         27         27         28              \n",
      "Weather Network        Not Found  Not Found  Not Found  Not Found  Not Found   \n",
      "Accurate Weather              28         28         28         27              \n",
      "\n",
      "                      Day_5  \n",
      "Sites                        \n",
      "Yahoo                    27  \n",
      "MSN Weather                  \n",
      "Weather Network   Not Found  \n",
      "Accurate Weather             \n"
     ]
    }
   ],
   "source": [
    "header = (\"Sites\", \"Current Weather\", \"Day_1\", \"Day_2\", \"Day_3\", \"Day_4\", \"Day_5\")\n",
    "dataset = [yahoo_data_now, msn_weather_now, weather_network_data_now, accurate_weather_now]\n",
    "df = pd.DataFrame(data=dataset, columns=header,)\n",
    "print search_text.title()+\"\\n\"\n",
    "print df.set_index(\"Sites\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
