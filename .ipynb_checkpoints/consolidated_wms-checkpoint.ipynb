{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy import Selector\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "from weather import Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "search_text = \"Chennai\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Yahoo Weather Information</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yahoo', 29, 28, 29, 29, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    weather = Weather()\n",
    "    location = weather.lookup_by_location(search_text)\n",
    "    condition = location.condition()\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), \"\", \"\", \"\")\n",
    "\n",
    "    yahoo_url = \"https://query.yahooapis.com/v1/public/yql?\"\n",
    "    yql_query = \"select * from weather.forecast where woeid in (select woeid from geo.places(1) where text='{}')\".format(search_text)\n",
    "    yql_url = yahoo_url + urllib.urlencode({'q':yql_query}) + \"&format=json\"\n",
    "    result = urllib2.urlopen(yql_url).read()\n",
    "    data = json.loads(result)\n",
    "\n",
    "    week_data = data['query']['results'][\"channel\"][\"item\"][\"forecast\"]\n",
    "    day_1 = int((int(week_data[1]['high']) - 32) * 0.5556)\n",
    "    day_2 = int((int(week_data[2]['high']) - 32) * 0.5556)\n",
    "    day_3 = int((int(week_data[3]['high']) - 32) * 0.5556)\n",
    "    day_4 = int((int(week_data[4]['high']) - 32) * 0.5556)\n",
    "    day_5 = int((int(week_data[5]['high']) - 32) * 0.5556)\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), day_1, day_2, day_3, day_4, day_5)\n",
    "except:\n",
    "    yahoo_data_now = (\n",
    "        \"Yahoo\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print yahoo_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>The Weather Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 29\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.theweathernetwork.com/in/api/location/search?searchText={}\".format(search_text)\n",
    "req = requests.get(base_url)\n",
    "\n",
    "data = req.json()\n",
    "data_url = []\n",
    "if data:\n",
    "    for i in data:\n",
    "        if i[\"name\"] == search_text.title() and i[\"country\"] == \"India\":\n",
    "            each_url = \"https://www.theweathernetwork.com{}\".format(i[\"url\"])            \n",
    "            data_url.append({\"each_url\": each_url, \"code\": i[\"code\"]})\n",
    "\n",
    "try:            \n",
    "    if data_url:\n",
    "    \n",
    "        req_url = data_url[0]\n",
    "        current_weather_url = \"https://www.theweathernetwork.com/in/api/savedlocation/index/?placecodes={}\".format(req_url[\"code\"])\n",
    "        current_weather_req = requests.get(current_weather_url).json()\n",
    "        current_day_temp = current_weather_req[0][\"temperature\"]\n",
    "    \n",
    "        resp = urllib2.urlopen(req_url[\"each_url\"]).read()\n",
    "        soup = BeautifulSoup(resp, \"lxml\")\n",
    "    \n",
    "        current_data_day_1 = soup.find_all(\"div\", attrs={\"class\": \"day_1\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_1[0])\n",
    "        selection_day_1 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_1 = re.findall(\"\\d+\", selection_day_1[5])[0]\n",
    "\n",
    "        current_data_day_2 = soup.find_all(\"div\", attrs={\"class\": \"day_2\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_2[0])\n",
    "        selection_day_2 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_2 = re.findall(\"\\d+\", selection_day_2[5])[0]\n",
    "\n",
    "        current_data_day_3 = soup.find_all(\"div\", attrs={\"class\": \"day_3\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_3[0])\n",
    "        selection_day_3 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_3 = re.findall(\"\\d+\", selection_day_3[5])[0]\n",
    "\n",
    "        current_data_day_4 = soup.find_all(\"div\", attrs={\"class\": \"day_4\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_4[0])\n",
    "        selection_day_4 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_4 = re.findall(\"\\d+\", selection_day_4[5])[0]\n",
    "\n",
    "        current_data_day_5 = soup.find_all(\"div\", attrs={\"class\": \"day_5\"})\n",
    "        body = \"\"\"{}\"\"\".format(current_data_day_5[0])\n",
    "        selection_day_5 = Selector(text=body).xpath(\"//div\").extract()\n",
    "        temp_day_5 = re.findall(\"\\d+\", selection_day_5[5])[0]\n",
    "\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            current_day_temp,\n",
    "            temp_day_1,\n",
    "            temp_day_2,\n",
    "            temp_day_3,\n",
    "            temp_day_4,\n",
    "            temp_day_5,\n",
    "        )\n",
    "    else:\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "        )\n",
    "except:\n",
    "        weather_network_data_now = (\n",
    "            \"Weather Network\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "            \"Not Found\",\n",
    "        )\n",
    "    \n",
    "#url = req.json()[0]['url']\n",
    "#code = req.json()[0]['code']\n",
    "\n",
    "#ddict = defaultdict(list)\n",
    "\n",
    "#for i in data:\n",
    "#    if ddict[i[\"countrycode\"]]:\n",
    "#        ddict[i[\"countrycode\"]].append(i)\n",
    "#    else:\n",
    "#        ddict[i[\"countrycode\"]] = []\n",
    "#        ddict[i[\"countrycode\"]].append(i)\n",
    "\n",
    "#info_urls = []        \n",
    "#for k in ddict[\"IN\"]:\n",
    "#    if k[\"name\"] == search_text.title():\n",
    "#        info_urls.append(k['code'])\n",
    "        \n",
    "#print info_urls        \n",
    "#try:\n",
    "#    if info_urls:\n",
    "#        data = \"https://www.theweathernetwork.com/in/api/savedlocation/index/?placecodes={}\".format(info_urls[0])\n",
    "#        print data\n",
    "#        url_req = requests.get(data)\n",
    "#        print url_req.json()\n",
    "#        temperature = url_req.json()[0]['temperature']\n",
    "#        feels_like = url_req.json()[0]['feels_like']\n",
    "#        updated = url_req.json()[0]['updatetime']\n",
    "#        weather_network_data_now = (\"Weather Network\", str(temperature), \"\", \"\", \"\", \"\", \"\")\n",
    "#    else:\n",
    "#        weather_network_data_now = (\n",
    "#            \"Weather Network\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#            \"Not Found\",\n",
    "#        )\n",
    "#except:\n",
    "#    weather_network_data_now = (\n",
    "#        \"Weather Network\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Found\",\n",
    "#        \"Not Foundr\",\n",
    "#        \"Not Found\",\n",
    "#    )\n",
    "#print weather_network_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> MSN Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    base_url = \"http://weather.service.msn.com/data.aspx?weasearchstr={}&culture=en-US&weadegreetype=F&src=outlook\".format(search_text)\n",
    "    req = requests.get(base_url)\n",
    "    root = ET.fromstring(req.content)\n",
    "    data = root.__dict__['_children'][0].__dict__['_children'][0].__dict__['attrib']\n",
    "    data_1 = root.__dict__['_children'][0].__dict__[\"_children\"][3].__dict__['attrib']['high']\n",
    "    data_2 = root.__dict__['_children'][0].__dict__[\"_children\"][4].__dict__['attrib']['high']\n",
    "    data_3 = root.__dict__['_children'][0].__dict__[\"_children\"][5].__dict__['attrib']['high']\n",
    "    msn_weather_now = (\n",
    "        \"MSN Weather\",\n",
    "        int((int(data['temperature'])-32)*float(0.5556)),\n",
    "        int((int(data_1)-32)*float(0.5556)),\n",
    "        int((int(data_2)-32)*float(0.5556)),\n",
    "        int((int(data_3)-32)*float(0.5556)),\n",
    "        \"\",\n",
    "        \"\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    msn_weather_now = (\n",
    "        \"MSN Weather\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print msn_weather_now    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4> Accurate Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "search_url = \"https://www.accuweather.com/en/search-locations\"\n",
    "search_data = {\"s\": search_text.title()}\n",
    "try:\n",
    "    req = requests.post(search_url, search_data)\n",
    "    resp = req.__dict__['_content']\n",
    "\n",
    "    soup = BeautifulSoup(resp, \"lxml\")\n",
    "    data_input_box = soup.find_all(\"input\", attrs={'id': 's'})\n",
    "\n",
    "    data_str = str(data_input_box[0])\n",
    "    data_url = re.findall(\"(https://www.accuweather.com/\\w+/\\w+/\\w+/[0-9]+/[\\w-]+/[0-9]+)\\\"\", data_str)[0]\n",
    "\n",
    "    base_url = data_url.replace(\"weather-forecast\", \"current-weather\")\n",
    "    base_link_url = base_url.replace(\"current-weather\", \"daily-weather-forecast\")\n",
    "    base_links = [\"{}?day={}\".format(base_link_url, i) for i in range(1, 6)]\n",
    "\n",
    "    req = urllib2.Request(base_url)\n",
    "    read_url = urllib2.urlopen(req)\n",
    "    response = read_url.read()\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    five_day_data = soup.find_all(\"li\", attrs={'data-href': base_links})\n",
    "\n",
    "    column_header = ('Day', 'Date', 'real_feel', 'precipitation', 'description')\n",
    "    data = []\n",
    "    for day in five_day_data:\n",
    "        hxs = HtmlXPathSelector(day).xpath(\"/html/body/p/text()\").extract()\n",
    "        doc = \"\"\"{}\"\"\".format(hxs[0].encode(\"utf-8\"))\n",
    "        each_day = re.sub(\"\\n+\",\n",
    "                          \",\",\n",
    "                          doc.decode(\"unicode_escape\").encode(\"ascii\", \"ignore\").replace(\"/\", \"\").replace(\"More\", \"\")\n",
    "                         )\n",
    "        data.append(filter(None, tuple(each_day.split(\",\")))) \n",
    "    accurate_weather_now = (\"Accurate Weather\", data[0][2], data[1][2], data[3][2], data[4][2], \"\", \"\")\n",
    "except:\n",
    "    accurate_weather_now = (\n",
    "        \"Accurate Weather\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "        \"Not Found\",\n",
    "    )\n",
    "print accurate_weather_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Consolidated Weather Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "header = (\"Sites\", \"Current Weather\", \"Day_1\", \"Day_2\", \"Day_3\", \"Day_4\", \"Day_5\")\n",
    "dataset = [yahoo_data_now, msn_weather_now, weather_network_data_now, accurate_weather_now]\n",
    "df = pd.DataFrame(data=dataset, columns=header,)\n",
    "print search_text.title()+\"\\n\"\n",
    "print df.set_index(\"Sites\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
