{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy import Selector\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "from weather import Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_text = \"Bangalore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h4>Yahoo Weather Information</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yahoo', 25, 26, 27, 28, 26, 27)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    weather = Weather()\n",
    "    location = weather.lookup_by_location(search_text)\n",
    "    condition = location.condition()\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), \"\", \"\", \"\")\n",
    "\n",
    "    yahoo_url = \"https://query.yahooapis.com/v1/public/yql?\"\n",
    "    yql_query = \"select * from weather.forecast where woeid in (select woeid from geo.places(1) where text='{}')\".format(search_text)\n",
    "    yql_url = yahoo_url + urllib.urlencode({'q':yql_query}) + \"&format=json\"\n",
    "    result = urllib2.urlopen(yql_url).read()\n",
    "    data = json.loads(result)\n",
    "\n",
    "    week_data = data['query']['results'][\"channel\"][\"item\"][\"forecast\"]\n",
    "    day_1 = int((int(week_data[1]['high']) - 32) * 0.5556)\n",
    "    day_2 = int((int(week_data[2]['high']) - 32) * 0.5556)\n",
    "    day_3 = int((int(week_data[3]['high']) - 32) * 0.5556)\n",
    "    day_4 = int((int(week_data[4]['high']) - 32) * 0.5556)\n",
    "    day_5 = int((int(week_data[5]['high']) - 32) * 0.5556)\n",
    "    yahoo_data_now = (\"Yahoo\", int((int(condition['temp'])-32)*float(0.5556)), day_1, day_2, day_3, day_4, day_5)\n",
    "except:\n",
    "    yahoo_data_now = (\"Yahoo\", \"Data Error\", \"Data Error\", \"Data Error\", \"Data Error\", \"Data Error\", \"Data Error\")\n",
    "print yahoo_data_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The Weather Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weather Network', 'Data Error', 'Data Error', 'Data Error', 'Data Error')\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.theweathernetwork.com/in/api/location/search?searchText={}\".format(search_text)\n",
    "req = requests.get(base_url)\n",
    "url = req.json()[0]['url']\n",
    "code = req.json()[0]['code']\n",
    "\n",
    "data = req.json()\n",
    "ddict = defaultdict(list)\n",
    "for i in data:\n",
    "    if ddict[i[\"countrycode\"]]:\n",
    "        ddict[i[\"countrycode\"]].append(i)\n",
    "    else:\n",
    "        ddict[i[\"countrycode\"]] = []\n",
    "        ddict[i[\"countrycode\"]].append(i)\n",
    "\n",
    "info_urls = []        \n",
    "for k in ddict[\"IN\"]:\n",
    "    if k[\"name\"] == search_text.title():\n",
    "        # info_urls.append(\"https://www.theweathernetwork.com{}\".format(k['url']))\n",
    "        info_urls.append(k['code']) \n",
    "try:\n",
    "    if info_urls:\n",
    "        data = \"https://www.theweathernetwork.com/in/api/savedlocation/index/?placecodes={}\".format(info_urls[0])\n",
    "        url_req = requests.get(data)\n",
    "        temperature = url_req.json()[0]['temperature']\n",
    "        feels_like = url_req.json()[0]['feels_like']\n",
    "        updated = url_req.json()[0]['updatetime']\n",
    "        weather_network_data_now = (\"Weather Network\", str(temperature), \"\", \"\", \"\")\n",
    "except:\n",
    "    weather_network_data_now = (\"Weather Network\", \"Data Error\", \"Data Error\", \"Data Error\", \"Data Error\")\n",
    "print weather_network_data_now    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> MSN Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MSN Weather', 27, '', '', '')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    base_url = \"http://weather.service.msn.com/data.aspx?weasearchstr={}&culture=en-US&weadegreetype=F&src=outlook\".format(search_text)\n",
    "    req = requests.get(base_url)\n",
    "    root = ET.fromstring(req.content)\n",
    "    data = root.__dict__['_children'][0].__dict__['_children'][0].__dict__['attrib']\n",
    "    msn_weather_now = (\"MSN Weather\", int((int(data['temperature'])-32)*float(0.5556)), \"\", \"\", \"\")\n",
    "except Exception as e:\n",
    "    msn_weather_now = (\"MSN Weather\", \"Location Not Found\", \"Location Not Found\", \"Location Not Found\", \"Location Not Found\")\n",
    "print msn_weather_now    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Accurate Weather </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accurate Weather', '28', '28', '28', '27')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:26: ScrapyDeprecationWarning: scrapy.selector.HtmlXPathSelector is deprecated, instantiate scrapy.Selector instead.\n"
     ]
    }
   ],
   "source": [
    "search_url = \"https://www.accuweather.com/en/search-locations\"\n",
    "search_data = {\"s\": search_text.title()}\n",
    "try:\n",
    "    req = requests.post(search_url, search_data)\n",
    "    resp = req.__dict__['_content']\n",
    "\n",
    "    soup = BeautifulSoup(resp, \"lxml\")\n",
    "    data_input_box = soup.find_all(\"input\", attrs={'id': 's'})\n",
    "\n",
    "    data_str = str(data_input_box[0])\n",
    "    data_url = re.findall(\"(https://www.accuweather.com/\\w+/\\w+/\\w+/[0-9]+/[\\w-]+/[0-9]+)\\\"\", data_str)[0]\n",
    "\n",
    "    base_url = data_url.replace(\"weather-forecast\", \"current-weather\")\n",
    "    base_link_url = base_url.replace(\"current-weather\", \"daily-weather-forecast\")\n",
    "    base_links = [\"{}?day={}\".format(base_link_url, i) for i in range(1, 6)]\n",
    "\n",
    "    req = urllib2.Request(base_url)\n",
    "    read_url = urllib2.urlopen(req)\n",
    "    response = read_url.read()\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    five_day_data = soup.find_all(\"li\", attrs={'data-href': base_links})\n",
    "\n",
    "    column_header = ('Day', 'Date', 'real_feel', 'precipitation', 'description')\n",
    "    data = []\n",
    "    for day in five_day_data:\n",
    "        hxs = HtmlXPathSelector(day).xpath(\"/html/body/p/text()\").extract()\n",
    "        doc = \"\"\"{}\"\"\".format(hxs[0].encode(\"utf-8\"))\n",
    "        each_day = re.sub(\"\\n+\",\n",
    "                          \",\",\n",
    "                          doc.decode(\"unicode_escape\").encode(\"ascii\", \"ignore\").replace(\"/\", \"\").replace(\"More\", \"\")\n",
    "                         )\n",
    "        data.append(filter(None, tuple(each_day.split(\",\")))) \n",
    "    accurate_weather_now = (\"Accurate Weather\", data[0][2], data[1][2], data[3][2], data[4][2])\n",
    "except:\n",
    "    accurate_weather_now = (\"Accurate Weathe\", \"Invalid Request\", \"Invalid Request\", \"Invalid Request\", \"Invalid Request\")\n",
    "print accurate_weather_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Consolidated Weather Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore\n",
      "\n",
      "                 Current Weather       Day_1       Day_2       Day_3\n",
      "Sites                                                               \n",
      "Yahoo                         25                                    \n",
      "MSN Weather                   27                                    \n",
      "Weather Network       Data Error  Data Error  Data Error  Data Error\n",
      "Accurate Weather              28          28          28          27\n"
     ]
    }
   ],
   "source": [
    "header = (\"Sites\", \"Current Weather\", \"Day_1\", \"Day_2\", \"Day_3\")\n",
    "dataset = [yahoo_data_now, msn_weather_now, weather_network_data_now, accurate_weather_now]\n",
    "df = pd.DataFrame(data=dataset, columns=header,)\n",
    "print search_text.title()+\"\\n\"\n",
    "print df.set_index(\"Sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
